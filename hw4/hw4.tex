%        File: hw4.tex
%     Created: Wed Oct 26 04:00 PM 2016 C
% Last Change: Wed Oct 26 04:00 PM 2016 C
%

\documentclass[a4paper]{article}

\title{CSci 5421 Homework 4 }
\date{11/9/16}
\author{Trevor Steil}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{esint}
\usepackage{enumitem}
\usepackage{algorithmicx}
\usepackage{algpseudocode}
\usepackage{algorithm}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem*{claim}{Claim}
\newtheorem*{problem}{Problem}
%\newtheorem*{lemma}{Lemma}
\newtheorem{definition}{Definition}[section]

\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\supp}[1]{\mathop{\mathrm{supp}}\left(#1\right)}
\newcommand{\lip}[1]{\mathop{\mathrm{Lip}}\left(#1\right)}
\newcommand{\curl}{\mathrm{curl}}
\newcommand{\la}{\left \langle}
\newcommand{\ra}{\right \rangle}
\renewcommand{\vec}[1]{\mathbf{#1}}

\newenvironment{solution}[1][]{\emph{Solution #1}}

\algnewcommand{\Or}{\textbf{ or }}
\algnewcommand{\And}{\textbf{ and }}

\begin{document}
\maketitle
\begin{enumerate}
  \item
    \begin{problem}

      Recall the problem of task scheduling with deadlines and penalties (Sec. 16.5), which was discussed in class. This was solved using the generic
      greedy algorithm for matroid optimization (Sec. 16.4). A key step in the algorithm is to test at each iteration whether a given set, $A$, of
      tasks is independent, i.e., whether there exists a schedule in which no task of $A$ is late. This can be accomplished by using the following
      fact: ``$A$ is independent if and only if $N_t(A) \leq t$ for $t=0,1,\dots,n$.'' Here $N_t(A)$ is the number of tasks in $A$ with deadline at
      most $t$.

      Give an algorithm that tests if $A$ is independent in $\Theta(|A|)$ time. Your answer should include a brief explanation of the key ideas behind
      your approach, pseudocode, and run-time analysis. (Note that a running time of $\Theta(n)$ is easy to achieve but is too large when $|A| \ll n$.)

      Hint: Consider limiting the range of values of $t$ that need to be checked in the fact stated above. Be sure to justify your reasoning.

    \end{problem}

    \begin{solution}

      We can design the test for independence based on the observation that $N_t(A) \leq |A|$ for all $t$. Therefore, we only need to check the
      condition $N_t(A) \leq t$ for $t=0,1,\dots,|A|$. We can use a table of size $|A|$ to calculate $N_t(A)$ for these values of $t$ as we scan over
      activities in $A$. We will use $d_i$ to represent the deadlines of tasks in $A$ (as was done in class). This gives the following algorithm:

      \begin{algorithmic}[1]
        \Function{Independent-Tasks}{$A$}

        \For{ $i \gets 1 .. |A|$ }
        \State $N[i] \gets 0$
        \EndFor

        \For{ $i \gets 1 .. |A|$ }
        \If{ $d_i \leq |A|$ }
        \State $N[d_i] \gets N[d_i] + 1$
        \EndIf
        \EndFor

        \For{ $i \gets 1 .. |A|$ }
        \If{ $N[i] > i$ }
        \Return $False$
        \EndIf
        \EndFor

        \Return $True$
        \EndFunction
      \end{algorithmic}

      This algorithm consists of a loop to initialize the array for storing $N_t(A)$, a loop to scan $d_i$ for, and a loop to see if $N_t(A) > t$ for
      any $0 \leq i \leq |A|$. All three of these loops take values $0 \leq i \leq |A|$, so the algorithm is $O(|A|)$. The first two loops listed have
      no way of exiting early and must take all possible values for $i$, so this algorithm is $\Theta(|A|)$.

    \end{solution}

  \item
    \begin{problem}

      Ex. 13.2-4

      Show that any arbitrary $n$-node binary search tree can be transformed into any other arbitrary $n$-node binary search tree using $O(n)$
      rotations. (Hint: First show that at most $n-1$ right rotations suffice to transform the tree into a right-going chain.)

      A careful, well-ordered answer should be given. Pseudocode is not required.

    \end{problem}

    \begin{solution}

    It suffices to show that any $n$-node binary search tree can be transformed into a
    right-going chain in $n-1$ rotations. This is because \texttt{LEFT-ROTATE} and \texttt{RIGHT-ROTATE} are inverses of each other. Let $T_1$ and
    $T_2$ are binary search trees with $n$ nodes. Let $R_1, \dots R_k$ be the right rotations necessary to transform $T_1$ into a right-going chain,
    that is, let
    \[ R_k ( R_{k-1}( \dots ( R_1(T_1) ) \dots) ) = C, \]
    where $C$ is a right-going chain of $n$ nodes. Similarly, let
    \[ \tilde{R}_l ( \tilde{R}_{l-1}( \dots ( \tilde{R}_1(T_2) ) \dots ) ) = C. \]
    Then letting $\tilde{L}_i = \tilde{R}_i^{-1}$ to be the corresponding left rotation which is the inverse of $\tilde{R}_i$ for all $i$, we have
    \begin{align*}
      T_2 &= \tilde{R}_1^{-1} ( \tilde{R}_2^{-1} ( \dots ( \tilde{R}_l^{-1} (C) ) \dots ) ) \\
      &= \tilde{L}_1 ( \tilde{L}_2 ( \dots ( \tilde{L}_l (C) ) \dots ) )
    \end{align*}

    Plugging in our expression for $C$ in terms of $T_1$, we get
    \[ T_2 = \tilde{L}_1 ( \dots ( \tilde{L}_l ( R_k( \dots R_1(T_1) \dots ) ) ) \dots ) .\]
    If $k \leq n-1$ and $l = n-1$, then $k+l \leq 2n - 2 = O(n)$, and we have $O(n)$ rotations that transform $T_1$ into $T_2$.

    Now we must show that we can transform an arbitrary $n$-node binary search tree into a right-going chain in $n-1$ rotations.

    Let $T$ be our original tree. In order to have a right-going chain, our tree must be traversable using only right-pointers. Define $G$ to be the
    set of nodes traversable using only right pointers. Initially, we must at least have $\texttt{root(T)} \in G$. So we must systematically add at
    most $n-1$ other nodes to $G$.

    Starting from \texttt{root(T)}, let $y$ be the first node in $T$ which has a left child, and let this left child be $x$. Because $y$ is the first
    node with a left child, performing a right rotation on $T$ at $y$ adds $x$ to the nodes traversable using only right pointers (as seen in Figure
    13.2 from the text). This rotation also leaves all right pointers as right pointers except for the right pointer beneath $x$ (as seen in Figure
    13.2 from the text), but $x$ was assumed
    to not be traversable using only right pointers, so no children of $x$ are traversable using only right pointers.

    Therefore, this right rotation adds $x$ to $G$, and removes zero elements from $G$. Recursively applying a right rotation to the first left
    pointer in $T$ will place every node in $G$ after at most $n-1$ iterations. At this point, every node is traversable using only right pointers,
    that is, $T$ has been transformed into a right-going chain after $n-1$ iterations.

    With the argument above, this completes the proof that any arbitrary $n$-node binary search tree can be transformed into any other $n$-node binary
    search tree in $O(n)$ rotations.

    \end{solution}

  \item

    \begin{problem}

      Problem 12-2

      Given two strings $a = a_0 a_1 \dots a_p$ and $b = b_0 b_1 \dots b_q$, where each $a_i$ and each $b_j$ is in some ordered set of characters, we
      say that string $a$ is \textbf{lexicographically less than} string $b$ if either
      \begin{enumerate}
        \item ther exists an integer $j$, where $0 \leq j \leq min(p,q)$, such that $a_i = b_i$ for all $i=0,1,\dots,j-1$ and $a_j < b_j$, or

        \item $p < q$ and $a_i = b_i$ for all $i = 0,1,\dots,p.$

      \end{enumerate}

      The \textbf{radix tree} data structure shown in Figure 12.5 stores the bit strings 1011, 10, 011, 100, and 0. When searching for a key $a = a_0
      a_1 \dots a_p$, we go left at a node of depth $i$ if $a_i = 0$ and right if $a_i = 1$. Let $S$ be a set of distinct bit strings whose lengths
      sum to $n$. Show how to use a radix tree to sort $S$ lexicographically in $\Theta(n)$ time.

      Describe, in words, the key ideas behind the tree-building and sorting algorithms, give pseudocode for both, and show that each takes
      $\Theta(n)$ time.

      Note that the radix tree is not given to you; you must build it from the given set of strings and then use this to sort. (So the time to sort
      includes the time to build the tree.) Note that there is no need to store the strings explicitly at the nodes; see the caption for Figure 12.5

    \end{problem}

    \begin{solution}

    \end{solution}

  \item

    \begin{problem}

      Ex. 13.3-5

      Professor Teach is concerned that \texttt{RB-INSERT-FIXUP} might set $T.nil.color$ to \texttt{RED}, in which case the test in line 1 would not cause
      the loop to terminate when $z$ is the root. Show that the professor's concern is unfounded by arguing that \texttt{RB-INSERT-FIXUP} never sets
      $T.nil.color$ to \texttt{RED}.

      A careful proof is expected. Consider using induction on $n$ and examining the various cases that can arise in \texttt{RB-INSERT-FIXUP} (see
      also Figures 13.5 and 13.6)).

    \end{problem}

    \begin{solution}

      Assume $T$ is the tree we have after the insertion of $z$, and the distance between $T.root$ and $z$ is $n$. We will show that assuming $T.nil.color = \texttt{BLACK}$
      before running $\texttt{RB-INSERT-FIXUP}(T,z)$, $T.nil.color$ will remain $\texttt{BLACK}$ after running $\texttt{RB-INSERT-FIXUP}(T,z)$.

      If $n = 0$, then $z = T.root$. Therefore, $z.p = T.nil$, which is assumed to satisfy $T.nil.color =
      \texttt{BLACK}$. Therefore, the \texttt{while} loop of $\texttt{RB-INSERT-FIXUP}(T,z)$ will be exited, leaving $T.nil.color$ unchanged.

      If $n = 1$, then $z$ is a child of $T.root$. By the loop invariant, we know $T.root.color = \texttt{BLACK}$, therefore, the $\texttt{while}$
      loop will be exited, leaving $T.nil.color$ unchanged.

      If $n = 2$, we can enter the $\texttt{while}$ loop. We must look at Case 1, Case 2, and Case 3 of the loop individually.
      If we are in Case 1, $z.p.p = T.root$. Therefore, the root, its children, and its grandchildren will have their colors changed. Then $T.root$
      will be assigned to $z$, putting us in the $n=0$ case for the next iteration.
      If we are in Case 3, $T.root$ and one of its children have their colors changed. Then a right rotation at $T.root$ is performed, which leaves $T.nil$
      unchanged. After this rotation, the distance between $z$ and $T.root$ will be reduced to $n=1$ for the next iteration.
      If we are in Case 2, $z.p$ is reassigned to $z$, reducing the distance between $z$ and $T.root$ to $n=1$, but then a left rotation rotates the
      new $z$ back to a distance of 2 from $T.root$. After this we are placed directly into Case 3, leaving $T.nil.color$ unchanged.

      For $n \geq 3$, assume we have the result for all distances to $T.root < n$. We have $\texttt{RB-INSERT-FIXUP}(T,z)$ only directly changes colors of
      $z, z.p,$ and $z.p.p$ as before. These leave $T.nil.color$ unchanged. Then $z$ is assigned to a node with a distance of $n-1$ or $n-2$ to
      $T.root$. By our inductive hypothesis, $T.nil.color$ remains unchanged from here.

      Therefore, $\texttt{RB-INSERT-FIXUP}(T,z)$ leaves $T.nil.color$ unchanged.

    \end{solution}

  \item

    \begin{problem}

      Problem 13.2 \textbf{Join operation on red-black trees}

      The \textbf{join} operation takes two dynamic sets $S_1$ and $S_2$ and an element $x$ such that for any $x_1 \in S_1$ and $x_2 \in S_2$, we have
      $x_1.key \leq x.key \leq x_2.key$. It returns a set $S = S_1 \cup \{x\} \cup S_2$. In this problem, we investigate how to implement the join
      operation on red-black trees.

      \begin{enumerate}
        \item Given a red-black tree $T$, let us store its black-height as the new attribute $T.bh.$ Argue that \texttt{TB-INSERT} and
          \texttt{RB-DELETE} can maintain the $bh$ attribute without requiring extra storage in the nodes of the tree and without increasing the
          asymptotic running times. Show that while descending through $T$, we can determine the black-height of each node we visit in $O(1)$ time per
          node visited.
      \end{enumerate}

      We wish to implement the operation \texttt{RB-JOIN($T_1,x,T_2$)}, which destroys $T_1$ and $T_2$ and returns a red-black tree $T = T_1 \cup
      \{x\} \cup T_2$. Let $n$ be the total number of nodes in $T_1$ and $T_2$.

      \begin{enumerate}[resume]

        \item
          Assume that $T_1.bh \geq T_2.bh$. Describe an $O(\lg n)$-time algorithm that finds a black node $y$ in $T_1$ with the largest key from among
          those nodes whose black-height is $T_2.bh$.

        \item Let $T_y$ be the subtree rooted at $y$. Describe how $T_y \cup \{x\} \cup T_2$ can replace $T_y$ in $O(1)$ time without destroying the
          binary-search-tree property.

        \item
          What color should we make $x$ so that red-black properties 1,3, and 5 are maintained? Describe how to enforce properties 2 and 4 in $O( \lg
          n)$ time.

        \item
          Skip because it is symmetric to part (b)

        \item
          Argue that the running time of \texttt{RB-JOIN} is $O( \lg n)$.

      \end{enumerate}

      Supplement your answer with short code fragments, as appropriate.

    \end{problem}

    \begin{solution}

      \begin{enumerate}
        \item
          The insertion and deletion operations have a running time of $O( \log n )$, where $n$ is the number of nodes in $T$. The black-height can be
          computed in $O( \log n )$ on its own, so we can compute this value separate from the insertion and deletion without affecting the asymptotic
          running time. The following pseudocode does this computation:

          \begin{algorithmic}[1]

            \Function{BLACK-HEIGHT}{$T$}

            \State $x \gets T.root$
            \State $T.bh \gets 0$

            \While{ $x \neq T.nil$ }
            \State $x \gets x.right$
            \If{ $x.color = \texttt{BLACK}$ }
            \State $T.bh \gets T.bh + 1$
            \EndIf
            \EndWhile

            \Return $T.bh$

            \EndFunction

          \end{algorithmic}

          Because the height of a red-black tree is $O( \log n )$, the \texttt{while} loop terminates in $O( \log n )$ iterations. Therefore, this
          algorithm has a running time of $O( \log n )$. The value computed above is the black-height because the black-height of a red-black tree is
          independent of the path taken to a leaf node.

          We can compute the black-height of nodes as we descend through the tree in $O(1)$ time per node in a similar way. We can initialize a
          counter with a value of $T.bh$ and decrease the value by 1 every time a \texttt{BLACK} node is passed. This process is demonstrated in the
          pseudocode of (b).

        \item
          Because $T$ is a red-black tree, every path from $T.root$ to an external leaf must contain the same number of black nodes. Therefore, we can
          start at $T.root$ and walk down the tree, choosing to go to the largest child at each step until the desired black height has been reached.
          The following pseudocode implements this strategy:

          \begin{algorithmic}

            \Function{FIND-MAX-KEY-BH-NODE}{$T_1, T_2$}

            \State $bh\_target \gets T_2.bh$
            \State $y \gets T_1.root$
            \State $bh\_curr \gets T_1.bh$

            \While{ $bh\_curr > bh\_target \Or y.color = \texttt{RED}$ }

            \State $y \gets y.right$

            \If{ $y.color = \texttt{BLACK}$ }
            \State $bh\_curr \gets bh\_curr - 1$
            \EndIf

            \EndWhile

            \Return y

            \EndFunction

          \end{algorithmic}

          This algorithm has a running time that is $O(\log n)$ because we are descending through a red-black tree, which has a height that is
          $O(\log n)$. The node $y$ that is returned will be a \texttt{BLACK} node because the \texttt{while} loop is only exited when $y.color =
          \texttt{BLACK}$. The black-height of $y$ is $T_2.bh$ because $bh\_curr$ starts at a value of $T_1.bh \geq T_2.bh$ and is decreased by at most 1 in
          every iteration of the \texttt{while} loop. $y$ has the largest key of all nodes satisfying these conditions because it was chosen to be the
          largest possible at every step, and the structure of the binary search tree prevents a choice other than the greedy choice from giving the
          optimal answer. \textbf{SHOULD PROBABLY PROVE THIS}

        \item
          Replacing $T_y$ with $T_y \cup \{x\} \cup T_2$ is just a matter of correctly pasting $x$ in place of $y$ and attaching $T_y$ and $T_2$ as subtrees.
          This can be done with the following pseudocode:

          \begin{algorithmic}

            \Function{TREE-MERGE}{$T_1, y, T_2, x$}

            \State $y.p.right \gets x$
            \State $x.p \gets y.p$
            \State $x.left \gets y$
            \State $y.p \gets x$
            \State $x.right \gets T_2.root$
            \State $T_2.root.p \gets x$

            \EndFunction

          \end{algorithmic}

          Inserting in this way preserves the binary search tree structure because we are assuming $x_1.key \leq x.key \leq x_2.key$ for all $x_1 \in
          T_1$ and $x_2 \in T_2$. Our pasting has put $x$ as far to the right as possible in $T_1$ with $T_y$ as its left subtree and $T_2$ as its
          right subtree. This is done in $O(1)$ time because we change a constant number of pointers.

        \item
          Choosing $x.color = \texttt{RED}$ will maintain properties 1,3, and 5. Properties 1 and 3 are obvious. Let $T$ be the new tree we have
          created. Because $T_1$ was originally a red-black tree and $x.color = \texttt{RED}$, any path from $T.root$ to a leaf node in $T \setminus
          T_2$ will have the same length. By the choice of $T_y.bh = T_2.bh$, any path from $T.root$ to a leaf in $T_2$ will have the same length as
          any path from $T.root$ to a leaf in $T_y$. Therefore, Property 5 is satisfied.

          By setting $x.color = \texttt{RED}$, we may be violating Properties 2 or 4. The structure of the violations of red-black properties is the
          same as when inserting a new node into a red-black tree (that is, we satisfy the same loop invariants), so we can restore the red-black
          properties in $O(\log n)$ time by running $\texttt{RB-INSERT-FIXUP}(T,x)$.

        \item
          Symmetric to (b)

        \item
          The operation \texttt{RB-JOIN} has a running time of $O(\log n)$ because we have found all of its pieces to have a running time of $O(\log
          n)$. If we continue with the assumption that $T_1.bh \geq T_2.bh$, we have the following pseudocode for \texttt{RB-JOIN}:

          \begin{algorithmic}

            \Function{RB-JOIN}{$T_1,x,T_2$}

            \State $y \gets \texttt{FIND-MAX-KEY-BH-NODE}(T_1,T_2)$
            \State \texttt{TREE-MERGE}$(T_1,y,T_2,x)$
            \State \texttt{RB-INSERT-FIXUP}$(T_1,x)$

            \EndFunction

          \end{algorithmic}

          We showed $\texttt{FIND-MAX-KEY-BH-NODE}$ runs in $O(\log n)$ time and \texttt{TREE-MERGE} runs in $O(1)$ time. Combining this with the fact
          that $\texttt{RB-INSERT-FIXUP}$ runs in $O(\log n)$ time, we have \texttt{RB-JOIN} runs in $O(\log n)$ time. (We are also implicitly using
          the $O(\log n)$ running-time to compute black-heights.)
      \end{enumerate}

    \end{solution}

  \item

    \begin{problem}

      Let $T$ be a red-black tree with $n$ nodes, where each node has the usual fields: key, color, and pointers to its parent and children. In
      addition, each internal node $x$ has an auxiliary field, \texttt{diff}, whose value is the difference between $x$'s key and the minimum key in
      the subtree rooted at $x$ (the subtree includes $x$). The auxiliary field is not of interest for external nodes.

      Argue carefully, using the General Augmentation Theorem (GAT), that the auxiliary field can be maintained during insertions and deletions
      without affecting the $O( \log n)$ time bounds for these operations. (You cannot store any other information in the nodes.)

      Note: You must use the GAT to make your argument, rather than trying to argue from first principles.

    \end{problem}

    \begin{solution}

    \end{solution}

\end{enumerate}
\end{document}


